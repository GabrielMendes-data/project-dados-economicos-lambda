# API Dados EconÃ´micos (AWS Lambda + Glue + Athena)

Este projeto coleta, transforma e armazena indicadores econÃ´micos provenientes de APIs pÃºblicas do Brasil e exterior.
A ingestÃ£o ocorre diariamente via **AWS Lambda**, os dados sÃ£o salvos em formato **Parquet particionado** no **Amazon S3**, e posteriormente disponibilizados para consulta SQL atravÃ©s do **AWS Glue Data Catalog** e **Amazon Athena**.

O objetivo Ã© criar uma pipeline simples, confiÃ¡vel e barata para centralizaÃ§Ã£o de indicadores como:

- SELIC diÃ¡ria
- Boletim Focus (Expectativas de Mercado â€” anual/mensal)
- DÃ³lar PTAX diÃ¡rio
- IPCA (IBGE)
- Taxas do Tesouro Direto

---

## ğŸ”¥ Principais funcionalidades

- Coleta automÃ¡tica de indicadores econÃ´micos via AWS Lambda
- TransformaÃ§Ã£o padronizada dos dados (schema consistente + metadados)
- Salvamento otimizado no S3 em **Parquet particionado por `dt_execucao`**
- CriaÃ§Ã£o de catÃ¡logo no **AWS Glue** para consulta via Athena
- ExecuÃ§Ã£o diÃ¡ria automÃ¡tica via **EventBridge Scheduler**
- Testes funcionais para validar construÃ§Ã£o das URLs e formataÃ§Ã£o de datas
- Suporte a execuÃ§Ã£o local para desenvolvimento e debug

---

## âœ” Tecnologias utilizadas

- **AWS Lambda** (Python runtime)
- **AWS EventBridge** (scheduler diÃ¡rio)
- **Amazon S3** (data lake)
- **AWS Glue Crawler + Glue Data Catalog**
- **Amazon Athena**
- Python 3.10+
- `requests`, `boto3`, `pandas`, `pyarrow`
- `pytest`

---

## ğŸ“‹ SumÃ¡rio

- [DescriÃ§Ã£o](#-descriÃ§Ã£o)
- [Arquitetura](#-arquitetura)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [VariÃ¡veis de ambiente](#-variÃ¡veis-de-ambiente)
- [ExecuÃ§Ã£o local](#-execuÃ§Ã£o-local)
- [ExecuÃ§Ã£o em ProduÃ§Ã£o](#-execuÃ§Ã£o-em-produÃ§Ã£o-lambda--eventbridge)
- [IntegraÃ§Ã£o com Glue e Athena](#-integraÃ§Ã£o-com-glue-e-athena)
- [Estrutura do projeto](#-estrutura-do-projeto)
- [Testes](#-testes)
- [ContribuiÃ§Ã£o](#-contribuiÃ§Ã£o)

---

## ğŸ“Œ DescriÃ§Ã£o

A funÃ§Ã£o principal `lambda_handler(event, context)` Ã© capaz de:

- Executar **uma API especÃ­fica** (filtro por `api_name`)
- Executar **todas as APIs simultaneamente** (usando `run_all: true`)
- Ajustar automaticamente para o **dia Ãºtil** mais prÃ³ximo (ignorando finais de semana e feriados)
- Transformar e padronizar os dados em um schema consistente
- Salvar em:
  - **S3** em formato JSON (ambiente local) ou **Parquet particionado** (em produÃ§Ã£o com Glue)
  - **AWS Glue Data Catalog** (metadados automÃ¡ticos)

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     EventBridge Scheduler                       â”‚
â”‚                    (diariamente Ã s 10:00 UTC)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AWS Lambda                                 â”‚
â”‚                   (main.lambda_handler)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ 1. Calcula data Ãºtil (ignorando fins de semana/feriados)  â”‚ â”‚
â”‚  â”‚ 2. Busca indicadores das APIs pÃºblicas                    â”‚ â”‚
â”‚  â”‚ 3. Transforma em schema padronizado                       â”‚ â”‚
â”‚  â”‚ 4. Escreve no S3                                          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Amazon S3 (Data Lake)                                â”‚
â”‚  s3://bucket/dados/economicos/                                 â”‚
â”‚  â”œâ”€â”€ selic/dt_execucao=YYYY-MM-DD/data.parquet               â”‚
â”‚  â”œâ”€â”€ focus/dt_execucao=YYYY-MM-DD/data.parquet               â”‚
â”‚  â”œâ”€â”€ dolar/dt_execucao=YYYY-MM-DD/data.parquet               â”‚
â”‚  â”œâ”€â”€ ibge/dt_execucao=YYYY-MM-DD/data.parquet                â”‚
â”‚  â””â”€â”€ tesouro/dt_execucao=YYYY-MM-DD/data.parquet             â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            AWS Glue Crawler (automÃ¡tico)                        â”‚
â”‚  Atualiza schema das tabelas a cada novo particionamento       â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         AWS Glue Data Catalog + Amazon Athena                  â”‚
â”‚  Consultas SQL ad-hoc em dados econÃ´micos histÃ³ricos            â”‚
â”‚                                                                 â”‚
â”‚  Exemplo:                                                       â”‚
â”‚  SELECT * FROM dados_economicos.selic                           â”‚
â”‚  WHERE dt_execucao >= '2025-11-01'                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… PrÃ©-requisitos

### Localmente

- **Python 3.10+**
- VariÃ¡veis de ambiente (arquivo `.env`)

### Em ProduÃ§Ã£o (AWS)

- **AWS Lambda** com role IAM que conceda:
  - `s3:GetObject`, `s3:PutObject` no bucket alvo
  - `glue:PutDataCatalogEncryptionSettings`, `glue:BatchCreatePartition` (optional, se usar Crawler)
- **AWS EventBridge** (scheduler)
- **AWS Glue Crawler** (optional, para atualizaÃ§Ã£o automÃ¡tica do catÃ¡logo)
- **Amazon Athena** (para consultas SQL)

---

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Clonar repositÃ³rio

```bash
git clone https://github.com/GabrielMendes-data/project-dados-economicos-lambda.git
cd project-dados-economicos-lambda
```

### 2. Criar ambiente virtual

```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

### 3. Instalar dependÃªncias

```powershell
pip install -r requirements.txt
```

---

## ğŸ” VariÃ¡veis de ambiente

Crie um arquivo `.env` na raiz do projeto com as variÃ¡veis abaixo:

```env
# ========== URLs das APIs ==========
BCB_SELIC_URL=https://api.bcb.gov.br/dados/serie/bcdata.sgs.1178/dados
BCB_FOCUS_URL=https://olinda.bcb.gov.br/olinda/servico/ExpectativasMercado/versao/v1/odata
BCB_DOLAR_URL=https://olinda.bcb.gov.br/olinda/servico/PTAX/versao/v1/odata/CotacaoDolarDia(dataCotacao=@dataCotacao)
IBGE_IPCA_URL=https://apisidra.ibge.gov.br/values
TESOURO_TAXAS_URL=https://www.tesourotransparente.gov.br/ckan/dataset/df56aa42-484a-4a59-8184-7676580c81e3/resource/796d2059-14e9-44e3-80c9-2d9e30b405c1/download
FERIADOS_URL=https://date.nager.at/api/v3/PublicHolidays

# ========== ConfiguraÃ§Ã£o de ExecuÃ§Ã£o ==========
BUCKET=seu-bucket-s3
ALL_APIS=selic,focus,dolar,ibge,tesouro
FOCUS_INDICATORS=Selic,IPCA,CÃ¢mbio
FOCUS_TEMPORAL_SERIES=anual,mensal

# ========== AWS (se usar em ProduÃ§Ã£o) ==========
AWS_REGION=sua-regiao
AWS_ACCESS_KEY_ID=seu-access-key
AWS_SECRET_ACCESS_KEY=sua-secret-key

# ========== Logging ==========
LOG_LEVEL=INFO
```

> **Nota:** Credenciais AWS podem tambÃ©m ser configuradas via:
> - VariÃ¡veis de ambiente: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`
> - Arquivo `~/.aws/credentials`
> - Perfil IAM (se executar em EC2 ou Lambda)

---

## ğŸš€ ExecuÃ§Ã£o local

### Executar o handler manualmente

```powershell
python main.py
```

O arquivo `main.py` possui um bloco `if __name__ == '__main__'` que executa exemplos.

### Exemplos de eventos

Invocar via Python REPL:

```python
from main import lambda_handler

# Executar uma API especÃ­fica
resultado = lambda_handler({
    "api_name": "selic",
    "date": "2025-11-14"
})
print(resultado)

# Executar todas as APIs
resultado = lambda_handler({
    "run_all": True,
    "date": "2025-11-14"
})
print(resultado)
```

---

## âš¡ ExecuÃ§Ã£o em ProduÃ§Ã£o (Lambda + EventBridge)

### 1. Preparar pacote ZIP ou container docker

```powershell
# Criar diretÃ³rio temporÃ¡rio
mkdir lambda-package
cd lambda-package

# Copiar cÃ³digo-fonte
cp -r ..\src .
cp -r ..\main.py .
cp -r ..\requirements.txt .

# Instalar dependÃªncias
pip install -r requirements.txt -t .

# Criar ZIP
Compress-Archive -Path * -DestinationPath function.zip

# Fazer upload para Lambda
# (via console AWS ou via CLI)
```

### 2. Configurar a funÃ§Ã£o Lambda

No **AWS Lambda Console**:

1. Criar funÃ§Ã£o: `nome-lambda`
2. Runtime: `Python 3.11` ou superior
3. Handler: `main.lambda_handler`
4. Timeout: `30 segundos` (mÃ­nimo recomendado)
5. Memory: `512 MB` (mÃ­nimo recomendado)
6. Adicionar as variÃ¡veis de ambiente (`.env`)
7. Anexar role IAM com permissÃµes de S3 e Glue

### 3. Agendar com EventBridge Scheduler

No **AWS EventBridge Console**:

1. Criar agendamento: `dados-economicos-diario`
2. FrequÃªncia: `cron(0 9 * * ? *)` (9:00 UTC, segunda a domingo)
3. Alvo: FunÃ§Ã£o Lambda `dados-economicos-lambda`
4. Payload de entrada (JSON):
   ```json
   {
     "run_all": true
   }
   ```

---

## ğŸ”— IntegraÃ§Ã£o com Glue e Athena

### AWS Glue Crawler

Para criar tabelas automaticamente no **Glue Data Catalog**:

1. No **AWS Glue Console**, criar Crawler:
   - Nome: `nome-crawler`
   - Fonte: S3 bucket `bucket-s3`
   - Banco de dados: `database` (criar se nÃ£o existir)

2. Executar crawler apÃ³s cada ingestÃ£o de dados (ou agendar).

---

## ğŸ“ Estrutura do projeto

```text
.
â”œâ”€â”€ conftest.py                      # ConfiguraÃ§Ãµes pytest
â”œâ”€â”€ Dockerfile                       # Container para Lambda
â”œâ”€â”€ main.py                          # Handler principal (lambda_handler)
â”œâ”€â”€ README.md                        # Este arquivo
â”œâ”€â”€ requirements.txt                 # DependÃªncias Python
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”œâ”€â”€ date.py                 # UtilitÃ¡rios de data e feriados
â”‚   â”‚   â”œâ”€â”€ logger.py               # ConfiguraÃ§Ã£o de logging centralizada
â”‚   â”‚   â””â”€â”€ transform_data.py       # TransformaÃ§Ãµes e factory de APIs
â”‚   â”‚
â”‚   â””â”€â”€ infra/
â”‚       â””â”€â”€ fetch_data.py           # Clientes HTTP (interfaces por API)

â””â”€â”€ tests/
    â””â”€â”€ test_fetch_data.py          # Testes funcionais das APIs
```

### DescriÃ§Ã£o dos mÃ³dulos

- **`main.py`**: Ponto de entrada. ContÃ©m `lambda_handler()` e lÃ³gica orquestradora.
- **`src/domain/date.py`**: CÃ¡lculo de datas Ãºteis, busca de feriados via API.
- **`src/domain/logger.py`**: ConfiguraÃ§Ã£o centralizada de logging (nÃ­vel via `LOG_LEVEL`).
- **`src/domain/transform_data.py`**: Classes de transformaÃ§Ã£o por API + factory pattern.
- **`src/infra/fetch_data.py`**: Classes abstratas e implementaÃ§Ãµes de clientes HTTP.
- **`tests/test_fetch_data.py`**: Testes funcionais (validam URLs e requisiÃ§Ãµes reais).

---

## ğŸ§ª Testes

### Executar todos os testes

```powershell
pytest -v
```

### Executar testes especÃ­ficos

```powershell
# Apenas testes de Selic
pytest tests/test_fetch_data.py::test_selic_build_url_and_fetch_data -v

# Com cobertura
pytest --cov=src --cov-report=html
```
---

## ğŸ¤ ContribuiÃ§Ã£o

1. **Fork** este repositÃ³rio.
2. Crie uma **branch** com nome descritivo:
   ```bash
   git checkout -b feature/nova-api-economica
   ```
3. FaÃ§a as mudanÃ§as e **adicione testes** (se aplicÃ¡vel).
4. Garanta que os testes passam:
   ```powershell
   pytest -q
   ```
5. Abra um **Pull Request** com descriÃ§Ã£o clara.

**Ãšltima atualizaÃ§Ã£o:** Novembro 2025
